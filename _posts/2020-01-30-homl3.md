---
layout: post
title: 3. Classification
category: Hands on Machine Learning
tag: Machine-Learning
---

 

## 1) MNIST

미국 고등학생과 인구조사국 직원들이 쓴 손글씨 데이터(0 부터 9 까지)이다. 총 데이터 셋의 개수는 7만 개이다. 6만 개를 훈련 세트로, 1만 개를 테스트 세트로 각각 할당한다.

```python
X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
```



<br/>

## 2) 이진 분류기

문제를 단순화해보자. 이를테면, 5인 것과 5가 아닌 것으로 분류하기로 하자. 이렇게 O와 X, 2개의 클래스로 분류하는 것을 이진 분류기(binary classifier)라고 한다. 본 문제에서는 이진 분류 모델로 확률적 경사 하강법(Stochastic Gradient Descent, SGD)을 사용한다. 사이킷런에서는 SGDClassifier를 제공한다.

```python
y_train_5 = (y_train == 5)
y_test_5 = (y_test == 5)

from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(max_iter=5, random_state=42)
sgd_clf.fit(X_train, y_train_5)
```



<br/>

## 3) 성능 측정

- 교차 검증을 사용한 정확도 측정

  - 교차검증 직접 구현하기 : 사이킷런이 제공하는 기능보다 교차 검증 과정을 더 많이 제어해야 할 필요가 있다. 이럴 때는 다음과 같은 코드로 cross_val_score() 함수를 직접 구현할 수 있다.

  ```python
  from sklearn.model_selection import StratifiedKFold
  from sklearn.base import clone
  
  skfolds = StratifiedKFold(n_splits=3, random_state=42)
  
  for train_index, test_index in skfolds.split(X_train, y_train_5):
      clone_clf = clone(sgd_clf)
      X_train_folds = X_train[train_index]
      X_train_folds = y_train_5[train_index]
      X_test_fold = X_train[test_index]
      X_test_fold = y_train_5[test_index]
      
      clone_clf.fit(X_train_folds, y_train_folds)
      y_pred = clone_clf.predict(X_test_fold)
      n_correct = sum(y_pred == y_test_fold)
      print(n_correct / len(y_pred))
  ```

  ※ (특히 불균형한 데이터에서는) __정확도를 분류기의 성능 측정 지표로 선호하지 않는다.__ 

- 오차 행렬 : 분류기의 성능을 평가하는 더 좋은 방법. '0'이 '1'로 잘못 분류된 횟수를 센다. 오차 행렬을 만들기 위해서는 실제 타깃과 비교할 수 있도록 먼저 예측값을 만들어야 한다. 사이킷런에서는 cross_val_predict() 함수를 제공한다.

  ```python
  from sklearn.model_selection import cross_val_predict
  y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
  
  from sklearn.metrics import confusion_matrix
  confusion_matrix(y_train_5, y_train_pred)
  >>[[53272, 1307]
     [ 1077, 4344]]
  ```

  - 오차 행렬의 행은 실제 클래스를 나타내고 열은 예측 클래스를 나타낸다.

  ```markdown
  |              | 5 가 아닌 것으로 판단 | 5 로 판단 |
  |--------------|-----------------------|-----------|
  | 실제로 5 (X) | 53272                 | 1307      |
  | 실제로 5 (O) | 1077                  | 4344      |
  ```

- 정밀도와 재현율

  - __정밀도__ (Precision)

  $$
  Precision = \frac{TP}{TP+FP}
  $$

  ​		$TP$ : 진짜 양성의 수,  $FP$ : 거짓 양성의 수

  - __재현율__ (Recall) : 민감도(sensitivity) 또는 진짜 양성 비율(true positive)이라고도 함
    $$
    Recall = \frac{TP}{TP+FN}
    $$
    $FN$ : 거짓 음성의 수

  - __F1 점수__ (F1 Score) : 정밀도와 재현율의 조화평균으로 구해진다

  $$
  F = \frac{2}{(1/Precision)+(1/Recall)} = \frac{TP}{TP+\frac{FN+FP}{2}}
  $$

  사이킷런에서는 F1 점수를 계산하는 f1_score() 함수를 제공한다.

  ```python
  from sklearn.metrics import f1_score
  f1_score(y_train_5, y_train_pred)
  ```

  - __정밀도/재현율 트레이드오프__ : 정밀도를 올리면 재현율이 줄고, 재현율을 높이면 정밀도가 내려감. 재현율에 대한 정밀도 그래프를 그려 적정 지점을 찾아내야 한다.

- __ROC 곡선__ (Receiver Operating Characteristic, 수신기 조작 특성) : 이진분류에서 널리 사용된다. 정밀도/재현율 곡선과 비슷하지만 다르다.

  - 거짓 양성 비율(FPR)에 대한 진짜 양성 비율(TPR, 재현율)의 곡선. 음성으로 정확하게 분류한 음성 샘플의 비율으로 구한다. FPR은 1에서 진짜 음성 비율(TNR, 특이도)을 뺀 값과도 같다.
  
  $$
  ROC\quad Curve = \frac{TPR}{FPR} = \frac{TPR}{1-TNR}
  $$
  
  - AUC : ROC 곡선 아래의 면적을 AUC라고 한다. 완전 랜덤한 분류기의 AUC는 0.5이며 완벽한 분류기의 AUC는 1입니다. 
  
  ![AUC](https://t1.daumcdn.net/cfile/tistory/262E8E3F544837AD27)
  
  

<br/>

## 4) 다중 분류



<br/>

## 5) 에러 분석



<br/>

## 6) 다중 레이블 분류

 

<br/>

## 7) 다중 출력 분류







