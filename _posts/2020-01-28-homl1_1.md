---
layout: post
title: 1-1. Machine Learning
category: Hands on Machine Learning
tag: Machine-Learning
---

 

## 1) 머신러닝이란?

머신러닝에 대한 정의

> "명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다." - Arthur Samuel, 1959
>
> "어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다." - Tom Michell, 1997

<br/>

## 2) 왜 머신러닝을 사용하는가?

전통적인 방법(사람이 모델을 만들어내는)으로는 __복잡한 문제__ (이를테면, 스팸 메일을 분류해주는 필터기)를 풀기 어렵다. 반면 __머신러닝 기법__ (어떤 메일이 스팸 메일인지 자동으로 기계가 학습)을 사용하면 __프로그램이 짧아져__ 유지보수하기 쉬우며 대부분 __정확도__ 가 더 높다.

<br/>

## 3) 머신러닝 시스템의 종류

- 지도학습과 비지도 학습

  - 지도 학습(Supervised Learning) : 알고리즘에 주입하는 훈련 데이터에 __레이블__ (label)이라는 원하는 답이 포함된다. ( _분류, 회귀 등_ )
    - k - 최근접 이웃(k-Nearest Neighbors, kNN)
    - 선형 회귀(Linear Regression)
    - 로지스틱 회귀(Logistic Regression)
    - 서포트 벡터 머신(Support Vector Machine, SVM)
    - 결정 트리(Decision Tree)와 랜덤 포레스트(Random Forest)
    - 신경망(Neural Networks)

  - 비지도 학습(Unsupervised Learning) : 시스템이 아무런 도움(레이블 사전 주입)없이 학습한다.
    - 군집(Clustering) : k-평균(k-Means), 계층 군집 분석(Hierarchical Cluster Analysis, HCA), 기댓값 최대화(Expectation Maximization)
    - 시각화(Visualization)와 차원축소(Dimensionality reduction) : 주성분 분석(Principal Component Analysis, PCA), 커널 PCA(kernal PCA), 지역적 선형 임베딩(Locally-Linear Embedding, LLE), t-SNE(t-distributed Stochastic Neighbor Embedding)
    - 연관 규칙 학습(Association rule learning) : 아프리오리(Apriori), 이클렛(Eclat)

  - 준지도 학습과 강화 학습  _(내용 추가 바람)_
    - 준지도 학습
    - 강화 학습

- 배치 학습과 온라인 학습
  - 배치 학습 : 데이터 셋을 미리 준비한 뒤 모든 데이터를 사용하여 학습. 방법이 간단하지만, 시스템이 빠르게 변화해야 하는 상황 혹은 너무 많은 데이터를 사용해야 하는 상황에서는 시간이 너무 지연된다. 이럴 때는 점진적으로 학습하는 알고리즘을 사용해야 한다.
  - 온라인 학습 : 데이터를 미니 배치라고 부르는 작은 묶음 단위로 주입. 아주 큰 데이터 셋도 다룰 수 있으며, 점진적으로 학습하므로 시스템이 미니 배치에 따라 변화할 수 있다.

- 사례 기반 학습과 모델 기반 학습
  - 사례 기반 학습 : 기계가 샘플을 기억한다. 이후 새로운 데이터가 들어오면 그 사례와 같은, 혹은 비슷한 정도(유사도)를 측정하여 일반화한다.
  - 모델 기반 학습 : 기계가 샘플을 통해 새로운 모델을 생성, 이를 훈련(Training)이라고 한다. 이를 기준으로 새로운 데이터를 일반화한다. 모델에는 그 모양을 결정하는 __파라미터__ (parameter)가 있다. 또, 만들어진 모델을 실제 데이터와 비교하여 평가하기 위한 함수들이 있다. <br/>[효용 함수(utility function, 모델이 얼마나 좋은지 평가)과 __비용 함수__ (cost function, 모델이 얼마나 나쁜지 평가)]

<br/>

## 4) 머신러닝의 주요 도전 과제

1. 충분하지 않은 양의 훈련 데이터
2. 대표성 없는 훈련 데이터
3. 낮은 품질의 데이터
4. 관련 없는 특성
5. 과대 적합과 과소적합

- 훈련 데이터 과대적합(Overfitting) : 훈련 데이터에 '너무' 잘 맞아 일반성이 떨어지는 경우
  - 해결 방법 : 파라미터 수가 적은 모델 선택, 훈련 데이터에 있는 특성 수 축소, 모델에 제약 가하기 등의 방법을 통해 모델을 단순화 / 훈련 데이터를 더 많이 모으기 / 훈련 데이터의 노이즈 줄이기(이상치 제거 등)

- 훈련 데이터 과소적합(Underfitting)
  - 해결 방법 : 파라미터 수가 더 많은 모델 선택 / 학습 알고리즘에 더 좋은 특성 제공 / 모델의 제약 줄이기

<br/>

## 5) 테스트와 검증

![TrainTestSet](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Machine_learning_nutshell_--_Split_into_train-test_set.svg/640px-Machine_learning_nutshell_--_Split_into_train-test_set.svg.png)

_(내용추가바람)_

<br/>

※ 첫 단원부터 다양한 머신러닝 기법을 설명하면서 듣도 보도 못한 용어가 많이 등장하여 당황하신 분도 계실 것입니다. 이번 단원에서는 그냥 이런 기법들이 있다는 것, 그리고 이후에 등장한다는 것만 알아두시고 넘어가면 좋을 것 같습니다.